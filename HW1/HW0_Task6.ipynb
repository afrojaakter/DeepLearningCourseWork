{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "\n",
      "\n",
      "Example Features: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "\n",
      "\n",
      "The shape of feature is (284807, 30) and target is (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import Sequential, metrics\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "    \n",
    "#dataset is collected from Kaggle computition \"Credit Card Fraud Detection\"\n",
    "dataPath = 'CreditCardFraudDetectionDataset\\\\creditcard.csv'\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "with open(dataPath) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"Header:\", line.strip()) # .strip() removes space before and after the string\n",
    "            continue #skip the header\n",
    "        fields = line.strip().split(\",\")\n",
    "        features.append([float(v.replace('\"\"', \"\")) for v in fields[:-1]])\n",
    "        targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"\\n\\nExample Features:\", features[-1])\n",
    "\n",
    "features = np.array(features, dtype = \"float32\") # storing feature data in a numpy array\n",
    "targets = np.array(targets, dtype = \"uint8\")\n",
    "print('\\n\\nThe shape of feature is {} and target is {}'.format(features.shape, targets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training samples: 227846 \n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "#Prepare training and validation dataset\n",
    "valid_samples = int(len(features)*0.2) # 20% of the dataset are validation data\n",
    "train_data = features[:-valid_samples]\n",
    "train_targets = targets[:-valid_samples]\n",
    "valid_data = features[-valid_samples:]\n",
    "valid_targets = targets[-valid_samples:]\n",
    "\n",
    "print(\"Number of Training samples: {} \\nNumber of validation samples: {}\"\n",
    "      .format(len(train_data), len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of the total)\n"
     ]
    }
   ],
   "source": [
    "#Analysing calss imbalance in the target data\n",
    "\n",
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\"Number of positive samples in training data: {} ({:0.2f}% of the total)\"\n",
    "      .format(counts[1], 100*float(counts[1])/len(train_targets)))\n",
    "\n",
    "weight_for_0 = 1.0/counts[0]\n",
    "weigth_for_1 = 1.0/counts[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Normalizing the data using training set satistics\n",
    "mean =  np.mean(train_data, axis = 0)\n",
    "train_data -= mean\n",
    "valid_data -= mean\n",
    "std = np.std(train_data, axis = 0)\n",
    "train_data /= std\n",
    "valid_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 28,928\n",
      "Trainable params: 28,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build a binary classification model\n",
    "\n",
    "model = Sequential(\n",
    "        [Dense(100, activation = 'relu', input_shape = (train_data.shape[-1],)),\n",
    "        Dense(128, activation = 'relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(100, activation = 'sigmoid'),\n",
    "        ]\n",
    ")\n",
    "model.summary()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\afroj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\afroj\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 227846 samples, validate on 56961 samples\n",
      "Epoch 1/16\n",
      " - 2s - loss: 3.6208e-05 - acc: 0.1981 - val_loss: 4.0113 - val_acc: 0.5359\n",
      "Epoch 2/16\n",
      " - 2s - loss: 2.8741e-05 - acc: 0.6913 - val_loss: 3.3827 - val_acc: 0.7773\n",
      "Epoch 3/16\n",
      " - 2s - loss: 1.8693e-05 - acc: 0.8220 - val_loss: 2.0516 - val_acc: 0.8535\n",
      "Epoch 4/16\n",
      " - 2s - loss: 1.0066e-05 - acc: 0.8743 - val_loss: 0.8685 - val_acc: 0.8906\n",
      "Epoch 5/16\n",
      " - 2s - loss: 6.8406e-06 - acc: 0.9026 - val_loss: 0.7285 - val_acc: 0.9126\n",
      "Epoch 6/16\n",
      " - 2s - loss: 6.3304e-06 - acc: 0.9204 - val_loss: 0.6948 - val_acc: 0.9271\n",
      "Epoch 7/16\n",
      " - 2s - loss: 6.0049e-06 - acc: 0.9326 - val_loss: 0.6364 - val_acc: 0.9374\n",
      "Epoch 8/16\n",
      " - 2s - loss: 5.1107e-06 - acc: 0.9415 - val_loss: 0.3231 - val_acc: 0.9451\n",
      "Epoch 9/16\n",
      " - 2s - loss: 4.4337e-06 - acc: 0.9482 - val_loss: 0.1685 - val_acc: 0.9511\n",
      "Epoch 10/16\n",
      " - 2s - loss: 4.1536e-06 - acc: 0.9536 - val_loss: 0.1034 - val_acc: 0.9558\n",
      "Epoch 11/16\n",
      " - 2s - loss: 4.0837e-06 - acc: 0.9579 - val_loss: 0.0867 - val_acc: 0.9597\n",
      "Epoch 12/16\n",
      " - 2s - loss: 3.9777e-06 - acc: 0.9614 - val_loss: 0.0855 - val_acc: 0.9630\n",
      "Epoch 13/16\n",
      " - 3s - loss: 3.9066e-06 - acc: 0.9644 - val_loss: 0.0884 - val_acc: 0.9657\n",
      "Epoch 14/16\n",
      " - 3s - loss: 3.8348e-06 - acc: 0.9669 - val_loss: 0.0741 - val_acc: 0.9680\n",
      "Epoch 15/16\n",
      " - 3s - loss: 3.8348e-06 - acc: 0.9691 - val_loss: 0.0925 - val_acc: 0.9701\n",
      "Epoch 16/16\n",
      " - 3s - loss: 3.8349e-06 - acc: 0.9710 - val_loss: 0.0722 - val_acc: 0.9718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2abacce0ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model with class_weight argument\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "class_weight = {0: weight_for_0, 1: weigth_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=16,\n",
    "    verbose=2,\n",
    "    validation_data=(valid_data, valid_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
